<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->





<title>Abhinav Java - Homepage</title>







<meta property="og:locale" content="en">
<meta property="og:site_name" content="Abhinav Java">
<meta property="og:title" content="Abhinav Java">


  <link rel="canonical" href="https://java-abhinav07.github.io/">
  <meta property="og:url" content="https://java-abhinav07.github.io/">


<!-- end SEO -->


<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    <link rel="apple-touch-icon" sizes="180x180" href="images/fish.png">
<link rel="icon" type="image/png" sizes="32x32" href="images/fish.png">
<link rel="icon" type="image/png" sizes="16x16" href="images/fish.png">
<link rel="manifest" href="images/site.webmanifest">

<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- Custom CSS for perfect circular profile image -->
<style>
.author__avatar img {
  width: 150px !important;
  height: 150px !important;
  object-fit: cover !important;
  border-radius: 50% !important;
  border: 3px solid #f2f3f3 !important;
}

@media (max-width: 57.8125em) {
  .author__avatar img {
    width: 100px !important;
    height: 100px !important;
  }
}
</style>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<![endif]-->
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg masthead__menu-home-item"><a href="#about-me">Homepage</a></li>
          
            <li class="masthead__menu-item"><a href="/#about-me">About Me</a></li>
          
            <li class="masthead__menu-item"><a href="/#-affiliations">Affiliations</a></li>
          
            <li class="masthead__menu-item"><a href="/#-publications-and-preprints">Selected Research Work</a></li>
          
            <li class="masthead__menu-item"><a href="/#-recent-updates">Recent Updates</a></li>
          
            <li class="masthead__menu-item"><a href="/#-misc">Misc</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div id="main" role="main">
      
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person" class="profile_box">

  <div class="author__avatar">
    <img src="assets/me.png" class="author__avatar" alt="Abhinav Java">
  </div>

  <div class="author__content">
    <h3 class="author__name">Abhinav Java</h3>
    <p class="author__bio">Microsoft Research, India</p>
  </div>

  <div class="author__urls-wrapper">
    <ul class="author__urls social-icons">
      
      
        <li><a href="mailto:java.abhinav99@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
        <li><a href="https://x.com/abhinav_java"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/java-abhinav07"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=g--_R9wAAAAJ&hl=en"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
        <li><a href="assets/AbhinavCV_2025.pdf"><i class="fas fa-fw fa-file-pdf" aria-hidden="true"></i> CV</a></li>
      

            

      
      
      
      
    </ul>
      <div class="author__urls_sm">
      
      
        <a href="mailto:java.abhinav99@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i></a>
      
      
       
      
        <a href="https://x.com/abhinav_java"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i></a>
      
      
      
      
      
      
      
      
      
      
        <a href="https://github.com/java-abhinav07"><i class="fab fa-fw fa-github" aria-hidden="true"></i></a>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <a href="https://scholar.google.com/citations?user=g--_R9wAAAAJ&hl=en"><i class="fas fa-fw fa-graduation-cap"></i></a>
      
      
        <a href="assets/AbhinavCV_2025.pdf"><i class="fas fa-fw fa-file-pdf" aria-hidden="true"></i></a>
      
      
      
      
    </div>
  </div>
</div>

  
  </div>

    
      <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
        <meta itemprop="headline" content="">
        <div class="page__inner-wrap">
          <section class="page__content" itemprop="text">
            
<!-- # Oop! I am updating this page. Please come back later. üòÑ -->
<p><span class="anchor" id="about-me"></span></p>
<h1 id="-about-me">ÔøΩ‚Äçüíª About Me</h1>


<p>Hi. My name is Abhinav Java. I'm a Research Fellow at Microsoft Research advised by Dr. Amit Sharma, Dr. Nagarajan Natarajan, Dr. Srivathsan Koundinyan, and Prof. Vineeth N Balasubramanian. 
Previously, I worked as a Research Associate at Adobe Media and Data Science Research Lab with Balaji Krishnamurthy and was fortunate to be advised by Prof. Chirag Agarwal at the University of Virginia. 
Even before that, I got my bachelor's degree in Computer Engineering from Delhi Technological University (DCE), India. During my undergraduate studies, I collaborated with the MIT Media Lab advised by Ayush Chopra and completed research internships at IIT Bombay and Adobe.

<h1 id="-affiliations">üè¢ Key Affiliations</h1>
<ul>
  <li><em>2024.08 - Present</em>     Research Fellow at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-india/">Microsoft Research</a>, Bengaluru, India</li>
  <li><em>2022.08 - 2024.08</em>     Research Associate 1, 2 at <a href="https://adobe.mdsr.live/">Adobe MDSR</a>, Noida, India</li>
  <li><em>2021</em>     Research Intern at <a href="https://adobe.mdsr.live/">Adobe MDSR</a>, Noida, India</li>
  <li><em>2018.05 - 2022.08</em>     Undergraduate Student at <a href="https://dtu.ac.in/">Delhi Technological University</a>, Delhi, India</li>

</ul>

<h1 id="-publications-and-preprints">üìù Selected Research Work</h1>

<p>* denotes equal contribution</p>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">NeurIPS Workshop 2025</div><img src="images/nicons/frugalrag.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><strong>FrugalRAG: Less is More in RL Finetuning for Multi-Hop Question Answering</strong></p>

    <p><strong>Abhinav Java</strong>, Srivathsan Koundinyan, Nagarajan Natarajan, Amit Sharma</p>

    <p><strong><em>NeurIPS Efficient Reasoning Workshop 2025</em></strong></p>


    <p><a href="https://arxiv.org/abs/2507.07634">[arXiv]</a>, <a href="https://github.com/microsoft/FrugalRAG">[Code]</a></p>

    <ul>
      <li>We present a post-training framework for SLM-based multi-hop question answering RAG Agents.</li>
      <li>We find that a two-stage curriculum that teaches policies to first explore exhaustively to maximize document recall and then learns when to stop is both data and compute efficient.</li>
    </ul>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">NeurIPS Workshop 2025</div><img src="images/nicons/livedrbench.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><strong>Characterizing Deep Research: A Benchmark and Formal Definition</strong></p>

    <p><strong>Abhinav Java*</strong>, Ashmit Khandelwal*, Sukruta Midigeshi*, Aaron Halfaker, Amit Deshpande, Navin Goyal, Ankur Gupta, Nagarajan Natarajan, Amit Sharma</p>

    <p><strong><em>NeurIPS Scaling Environments for Agents Workshop 2025</em></strong></p>


    <p><a href="https://arxiv.org/abs/2508.04183">[arXiv]</a>, <a href="https://huggingface.co/datasets/microsoft/LiveDRBench">[Dataset]</a></p>

    <ul>
      <li>We present a formal definition of deep research and an objective benchmark comprising 8 different domains (Science, Everyday Use, Prior Art, etc).</li>
      <li>We find that even frontier models like OpenAI DR, Gemini DR, and Perplexity achieve a modest F1 score of <=55% on our benchmark.</li>
    </ul>

  </div>
</div>


<div class="paper-box"><div class="paper-box-image"><div><div class="badge">NeurIPS Workshop 2025</div><img src="images/nicons/task-transfer.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><strong>Understanding Task Transfer in VLMs</strong></p>

    <p><strong>Bhuvan Sachdeva*</strong>, Karan Uppal*, <strong>Abhinav Java*</strong>, Vineeth N Balasubramanian</p>

    <p><strong><em>NeurIPS UniReps Workshop 2025</em></strong></p>


    <p>[arXiv will be released soon!], [Code will be released soon!]</p>

    <ul>
      <li>We present a comprehensive analysis of zero-shot task-transfer in VLMs across 10+ datasets and three models.</li>
      <li>We introduce a novel metric to quantify cross-task influence in VLM finetuning.</li>
      <li>Our analysis reveals actionable insights ‚Äì beneficial task cliques and transfer trends for effective finetuning strategies.</li>
    </ul>

  </div>
</div>


<div class="paper-box"><div class="paper-box-image"><div><div class="badge">NAACL (Main) 2025</div><img src="images/nicons/regtext.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><strong>Towards Operationalizing Right to Data Protection</strong></p>

    <p><strong>Abhinav Java*</strong>, Simra Shahid*, Chirag Agarwal</p>

    <p><strong><em>NAACL (Main) 2025</em></strong></p>


    <p><a href="https://arxiv.org/abs/2411.08506">[arXiv]</a>, <a href="https://github.com/AikyamLab/regtext">[Code]</a></p>

    <ul>
      <li>We present a framework for generating unlearnable text datasets. These datasets prevent data misuse by failing on test datasets despite converging normally during training.</li>
      <li>We show that imperceptible perturbations can expose vulnerabilities of strong models like GPT-4, dropping their performance on sentiment analysis tasks below the zero-shot baseline.</li>
    </ul>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">WACV 2025</div><img src="images/nicons/reedit.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><strong>ReEdit: Multimodal Exemplar-Based Image Editing</strong></p>

    <p><strong>Ashutosh Srivastava*</strong>, Tarun Menta*, <strong>Abhinav Java*</strong>, Avadhoot Jadhav, Silky Singh, Surgan Jandial, Balaji Krishnamurthy</p>

    <p><strong><em>WACV 2025</em></strong></p>


    <p><a href="https://arxiv.org/abs/2411.03982">[arXiv]</a>, <a href="https://reedit-diffusion.github.io/">[Code]</a></p>

    <ul>
      <li>We present an efficient inference time approach for image editing using edit exemplars.</li>
      <li>We find that textual descriptions are not enough to perform faithful edits, incorporating edits in both image and text modality.</li>
    </ul>

  </div>
</div>


<div class="paper-box"><div class="paper-box-image"><div><div class="badge">AAAI 2024</div><img src="images/nicons/cafie.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><strong>All Should Be Equal in the Eyes of LMs: Counterfactually Aware Fair Text Generation</strong></p>

    <p><strong>Pragyan Banerjee*</strong>, <strong>Abhinav Java*</strong>, Surgan Jandial*, Simra Shahid*, Shaz Furniturewala, Balaji Krishnamurthy, Sumit Bhatia</p>

    <p><strong><em>AAAI 2024</em></strong></p>


    <p><a href="https://arxiv.org/abs/2311.05451">[arXiv]</a>, <a href="https://github.com/banerjeepragyan/CAFIE/">[Code]</a></p>

    <ul>
      <li>We present a framework to steer models towards unbiased generations using counterfactual contexts.</li>
      <li>We find that re-weighing logits using probabilities distributions can encourage equitable responses across several benchmarks for varying model sizes.</li>
    </ul>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">WACV 2023</div><img src="images/nicons/monomer.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><strong>One Shot Doc Snippet Detection: Towards Search in Document Beyond Text</strong></p>

    <p><strong>Abhinav Java</strong>, Shripad Deshmukh, Milan Aggarwal, Surgan Jandial, Mausoom Sarkar, Balaji Krishnamurthy</p>

    <p><strong><em>WACV 2023</em></strong></p>


    <p><a href="https://openaccess.thecvf.com/content/WACV2023/papers/Java_One-Shot_Doc_Snippet_Detection_Powering_Search_in_Document_Beyond_Text_WACV_2023_paper.pdf">[arXiv]</a></p>

    <ul>
      <li>We highlight a new problem in document object detection of searching for arbitrary snippets using a novel example snippet.</li>
      <li>To solve this, we generate a large scale training dataset using rudimentary object structures and propose a new architecture that fuses various modalities.</li>
    </ul>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">ECCV 2022</div><img src="images/nicons/cbns.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><strong>Learning to Censor by Noisy Sampling</strong></p>

    <p>Ayush Chopra, <strong>Abhinav Java</strong></a>, Abhishek Singh</a>, Vivek Sharma</a>, Ramesh Raskar</a></p>

    <p><strong><em>ECCV 2022</em></strong></p>


    <p><a href="https://arxiv.org/abs/2203.12192">[arXiv]</a>, <a href="https://github.com/java-abhinav07/CBNS-ECCV2022">[Code]</a></p>

    <ul>
      <li>We present an end-to-end differentiable sampler to protect 3D point clouds from perception attacks.</li>
      <li>Our key insight is to leverage the localized saliency of perception tasks on point clouds to provide good privacy-utility trade-offs .</li>
    </ul>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">NeurIPS 2021 Workshop</div><img src="images/nicons/benford.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><strong>Rethinking Neural Networks With Benford's Law</strong></p>

    <p>Surya Kant Sahu, <strong>Abhinav Java</strong>, Arshad Shaikh, Yannic Kilcher</p>

    <p><strong><em>NeurIPS ML4 Physical Sciences 2022</em></strong></p>


    <p><a href="https://arxiv.org/pdf/2102.03313">[arXiv]</a>, <a href="https://github.com/The-Learning-Machines/RethinkingNNsWithBL">[Code]</a></p>

    <ul>
      <li>We study: Is the distribution of the Neural Network parameters related to the network‚Äôs generalization capability? </li>
      <li>We define a new metric called Model Enthalpy which measures the closeness of NN parameters to the ideal Benford's distribution and provide experimental evidence that this metric can be used for Early Stopping for training shallow networks.</li>
    </ul>

  </div>
</div>


<h1 id="-recent-updates">üì¢ Recent Updates</h1>
<ul>
  <li><em>Oct 2025</em> <strong>FrugalRAG</strong> is accepted to the NeurIPS 2025 Workshop on <em>Efficient Reasoning</em>. Official code: <a href="https://github.com/microsoft/FrugalRAG">github.com/microsoft/FrugalRAG</a>.</li>
<li><em>Sept 2025</em> Participated in a <strong>Fireside Chat on Deep Research</strong> at Plutos Dev.</li>
  <li><em>Sep 2025</em> <strong>LiveDRBench</strong> ‚Äî released on Hugging Face and accepted at the NeurIPS 2025 Workshop on <em>Scaling Environments for Agents</em>. <a href="https://huggingface.co/datasets/microsoft/LiveDRBench">Hugging Face</a>.</li>
<li><em>Aug 2025</em> Gave a career talk at <strong>DTU AI Summer School</strong>.</li>
  <li><em>Aug 2025</em> Understanding <strong>Task Transfer</strong> in VLMs, our analysis paper is accepted at NeurIPS 2025 Workshop on <em>Unifying Representations in Neural Models</em>.</li>
  <li><em>Jul 2025</em> Attended <strong>ICML 2025</strong> in Vancouver (July 13‚Äì19) to present FrugalRAG.</li>
  <li><em>Jun 2025</em> Faster and flexible SLMs for retrieval intensive reasoning! <strong>FrugalRAG</strong> is accepted at ICML EsFoMo workshop. Preprint: <a href="https://arxiv.org/pdf/2507.07634">arXiv:2507.07634</a>.</li>
  <li><em>Feb 2025</em> <strong>Unlearnable Text Datasets</strong> accepted at <em>NAACL 2025 (Main)</em>. Code released: <a href="https://github.com/AikyamLab/regtext">GitHub</a>.</li>
  <li><em>Nov 2024</em> Want to edit images without long, descriptive prompts? Use <strong>ReEdit</strong>! Our latest work on Exemplar-Based Image Editing accepted at <em>WACV 2025</em> and <em>ECCV-AI4VA 2024</em>. Code available at <a href="https://reedit-diffusion.github.io/">Project page</a>.</li>
  <li><em>Sep 2024</em> <strong>Thinking Fair and Slow</strong> is accepted at <em>EMNLP 2024 (Main)</em>! We show how effective structured prompting really is for debiasing LLMs.</li>
  <li><em>Aug 2024</em> Joined <strong>Microsoft Research India</strong> as a Pre-Doctoral Research Fellow.</li>
</ul>

<h1 id="-services">üóí Services</h1>
<ul>
  <li><strong>Reviewer</strong>: ICLR ‚Äô26, CVPR ‚Äô25, KDD ‚Äô24, CVPR‚Äô24, U&ME@ECCV‚Äô24, WACV‚Äô23, ML4PS@NeurIPS‚Äô22, ECCV‚Äô22
 </li>
</ul>
<!-- 
# üí¨ üíªInvited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

<h1 id="-misc">‚öΩ Misc</h1>
<ul>
  <li>I love playing and watching football. In a past life, I used to represent my high school and college football team.</li>
</ul>

          </section>
        </div>
      </article>
    </div>

    <script src="assets/js/main.min.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3CXTTZKE7K"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', "G-3CXTTZKE7K");
</script>

<!-- Statcounter code for My homepage https://java-abhinav07.github.io/ on
Google Sites (new) -->
<script type="text/javascript">
  var sc_project=12834493; 
  var sc_invisible=1; 
  var sc_security="6f019326"; 
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js" async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
  href="https://statcounter.com/" target="_blank"><img class="statcounter"
  src="https://c.statcounter.com/12834493/0/6f019326/1/" alt="Web Analytics"
  referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
  <!-- End of Statcounter Code -->


<script>
    $(document).ready(function () {
        
        var gsDataBaseUrl = 'https://cdn.jsdelivr.net/gh/YoungXinyu1802/java-abhinav07.github.io@'
        
        $.getJSON(gsDataBaseUrl + "google-scholar-stats/gs_data.json", function (data) {
            var totalCitation = data['citedby']
            document.getElementById('total_cit').innerHTML = totalCitation;
            var citationEles = document.getElementsByClassName('show_paper_citations')
            Array.prototype.forEach.call(citationEles, element => {
                var paperId = element.getAttribute('data')
                var numCitations = data['publications'][paperId]['num_citations']
                element.innerHTML = '| Citations: ' + numCitations;
            });
        });
    })
</script>

<footer style="text-align: center; padding: 2em 0; margin-top: 3em; border-top: 1px solid #f2f3f3; color: #7a8288; font-size: 0.9em;">
  <p>Template inspired by <a href="https://github.com/RayeRen/acad-homepage.github.io" target="_blank" style="color: #2471a3;">RayeRen/acad-homepage.github.io</a> and <a href="https://youngxinyu1802.github.io/" target="_blank" style="color: #2471a3;">youngxinyu1802.github.io</a></p>
</footer>

  </body>
</html>
