@inproceedings{furniturewala-etal-2024-thinking,
    title = "{``}Thinking{''} Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models",
    author = "Furniturewala*, Shaz  and
      Jandial*, Surgan  and
      Java, Abhinav  and
      Banerjee, Pragyan  and
      Shahid, Simra  and
      Bhatia, Sumit  and
      Jaidka, Kokil",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.13",
    doi = "10.18653/v1/2024.emnlp-main.13",
    pages = "213--227",
    abstract = "Existing debiasing techniques are typically training-based or require access to the model{'}s internals and output distributions, so they are inaccessible to end-users looking to adapt LLM outputs for their particular needs. In this study, we examine whether structured prompting techniques can offer opportunities for fair text generation. We evaluate a comprehensive end-user-focused iterative framework of debiasing that applies System 2 thinking processes for prompts to induce logical, reflective, and critical text generation, with single, multi-step, instruction, and role-based variants. By systematically evaluating many LLMs across many datasets and different prompting strategies, we show that the more complex System 2-based Implicative Prompts significantly improve over other techniques demonstrating lower mean bias in the outputs with competitive performance on the downstream tasks. Our work offers research directions for the design and the potential of end-user-focused evaluative frameworks for LLM use.",
}